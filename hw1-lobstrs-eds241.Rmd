---
title: "Assignment 1"
subtitle: "California Spiny Lobster (*Panulirus Interruptus*): Assessing the Impact of Marine Protected Areas (MPAs) at 5 Reef Sites in Santa Barbara County" 
author: "EDS 241 / ESM 244 (**Due: 1/17**)"
date: "1/8/26"
output: 
    html_document:
      theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=FALSE, warning = FALSE, message = FALSE )
```

------------------------------------------------------------------------

![](figures/spiny2.jpg)

------------------------------------------------------------------------

### Assignment Instructions:

-  Working with partners to troubleshoot code and concepts is encouraged! If you work with a partner, please list their name next to yours at the top of your assignment so Annie and I can easily see who collaborated. 

-  All written responses must be written independently (**in your own words**). 

-  Please follow the question prompts carefully and include only the information each question asks in your submitted responses.

-  Submit both your knitted document and the associated `RMarkdown` or `Quarto` file. 

-  Your knitted presentation should meet the quality you'd submit to research colleagues or feel confident sharing publicly. Refer to the rubric for details about presentation standards.


**Assignment submission (YOUR NAME):** ______________________________________


----------------------------------------------------------------------

```{r}

library(tidyverse)
library(here)
library(janitor)
library(estimatr)  
library(performance)
library(jtools)
library(gt)
library(gtsummary)
library(interactions) 

```

------------------------------------------------------------------------

#### DATA SOURCE:

> [Reed D. 2019. SBC LTER: Reef: Abundance, size and fishing effort for California Spiny Lobster (Panulirus interruptus), ongoing since 2012. Environmental Data Initiative.](https://doi.org/10.6073/pasta/a593a675d644fdefb736750b291579a0) Data accessed 11/17/2019.

------------------------------------------------------------------------

### **Introduction**

You're about to dive into some deep data collected from five reef sites in Santa Barbara County, all about the abundance of California spiny lobsters! ðŸ¦ž Data was gathered by divers annually from 2012 to 2018 across Naples, Mohawk, Isla Vista, Carpinteria, and Arroyo Quemado reefs.

Why lobsters? Well, this sample provides an opportunity to evaluate the impact of Marine Protected Areas (MPAs) established on January 1, 2012 (Reed, 2019). Of these five reefs, Naples, and Isla Vista are MPAs, while the other three are not protected (non-MPAs). Comparing lobster health between these protected and non-protected areas gives us the chance to study how commercial and recreational fishing might impact these ecosystems.

We will consider the MPA sites the `treatment` group and use regression methods to explore whether protecting these reefs really makes a difference compared to non-MPA sites (our control group). In this assignment, weâ€™ll think deeply about which causal inference assumptions hold up under the research design and identify where they fall short. 

Letâ€™s break it down step by step and see what the data reveals! ðŸ“Š

![](figures/map-5reefs.png)


------------------------------------------------------------------------

#### Step 1: Anticipating potential sources of selection bias

**a.** Do the control sites (Arroyo Quemado, Carpenteria, and Mohawk) provide a strong counterfactual for our treatment sites (Naples, Isla Vista)? Write a paragraph making a case for why this comparison is ceteris paribus or whether selection bias is likely (be specific!).  

Finding a perfect counterfactual is a difficult task to do. In this study, there are three control sites and two treatment sites. The size and lobster populations of all the sites is a feature that is difficult to control for. Although there is a control and treatment group assigned randomly, ommitted variable bias still appears within this sample design, therefore selection bias is likely because the control and treatment could be more similar. 

------------------------------------------------------------------------

#### Step 2: Read & wrangle data

**a.** Read in the raw data from the "data" folder named `spiny_abundance_sb_18.csv`. Name the data.frame `rawdata`

**b.** Use the function `clean_names()` from the `janitor` package

```{r}
# HINT: check for coding of missing values (`na = "-99999"`)

rawdata <- read_csv(here("data", "spiny_abundance_sb_18.csv"), 
                    na = "-99999") %>% # Handle missing values as NAs
    janitor::clean_names() 

```

**c.** Create a new `df` named `tidyata`. Using the variable `site` (reef location) create a new variable `reef` as a `factor` and add the following labels in the order listed (i.e., re-order the `levels`): 
    
    "Arroyo Quemado", "Carpenteria", "Mohawk", "Isla Vista",  "Naples"

```{r}

tidydata <- rawdata %>% 
    # Create new column reef as a factor
  mutate(reef = factor(site, 
                       # Specify site levels in order of new labels 
                       levels = c("AQUE", "CARP", "MOHK", "IVEE", "NAPL"), 
                       # Specify new levels 
                       labels = c("Arroyo Quemado", "Carpenteria", "Mohawk", "Isla Vista", "Naples")))

    
```

Create new `df` named `spiny_counts` 

**d.** Create a new variable `counts` to allow for an analysis of lobster counts where the unit-level of observation is the total number of observed lobsters per `site`, `year` and `transect`. 

- Create a variable `mean_size` from the variable `size_mm`
- NOTE: The variable `counts` should have values which are integers (whole numbers). 
- Make sure to account for missing cases (`na`)!

**e.** Create a new variable `mpa` with levels `MPA` and `non_MPA`. For our regression analysis create a numerical variable `treat` where MPA sites are coded `1` and non_MPA sites are coded `0`

```{r}
#HINT(d): Use `group_by()` & `summarize()` to provide the total number of lobsters observed at each site-year-transect row-observation. 

#HINT(e): Use `case_when()` to create the 3 new variable columns

    # ......Step d...... 
spiny_counts <- tidydata %>% 
    # Group by site, year, and transect
    group_by(site, year, transect) %>% 
    # Count the number of rows in each group
    mutate(counts = n()) %>% 
    # Create new column
    mutate(mean_size = mean(size_mm, na.rm = TRUE)) %>% 
    # ungroup 
    ungroup() %>% 
# ...... Step e.....
    # Create new mpa column specifying which sites are MPA and non_MPA
    mutate(mpa = case_when(
        site == 'IVEE' ~ 'MPA',
        site == 'NAPL' ~ 'MPA', 
        site == 'AQUE' ~ 'non_MPA',
        site == 'CARP' ~ 'non_MPA', 
        site == 'MOHK' ~ 'non_MPA')) %>% 
    # Create new treat column with 1 for MPA and 0 for non MPA
    mutate(treat = case_when(
       mpa == "MPA" ~ 1, 
       mpa == "non_MPA" ~ 0
    ))

```

> NOTE: This step is crucial to the analysis. Check with a friend or come to TA/instructor office hours to make sure the counts are coded correctly!

------------------------------------------------------------------------

#### Step 3: Explore & visualize data

**a.** Take a look at the data! Get familiar with the data in each `df` format (`tidydata`, `spiny_counts`)

**b.** We will focus on the variables `count`, `year`, `site`, and `treat`(`mpa`) to model lobster abundance. Create the following 4 plots using a different method each time from the 6 options provided. Add a layer (`geom`) to each of the plots including informative descriptive statistics (you choose; e.g., mean, median, SD, quartiles, range). Make sure each plot dimension is clearly labeled (e.g., axes, groups).

- [Density plot](https://r-charts.com/distribution/density-plot-group-ggplot2)
- [Ridge plot](https://r-charts.com/distribution/ggridges/)
- [Jitter plot](https://ggplot2.tidyverse.org/reference/geom_jitter.html) 
- [Violin plot](https://r-charts.com/distribution/violin-plot-group-ggplot2) 
- [Histogram](https://r-charts.com/distribution/histogram-density-ggplot2/) 
- [Beeswarm](https://r-charts.com/distribution/beeswarm/)

Create plots displaying the distribution of lobster **counts**:

1) grouped by reef site  
2) grouped by MPA status
3) grouped by year

Create a plot of lobster **size** :

4) You choose the grouping variable(s)!

```{r, fig.cap= "Fig 1. Distribution of Lobster Counts by Site."}
# plot 1: ....
spiny_counts %>%
    # Plot the counts
  ggplot(aes(x = counts)) +
  geom_histogram(aes(y = ..density..),
                 colour = "black", fill = "white") +
  geom_density(lwd = 0.8, linetype = 1, colour = "#EA7769") +
  # Seperate by site 
    facet_wrap(~site) +
  labs(title = "Distribution of Lobster Counts by Site", x = "Lobster Count", y = "Density") +
    theme(plot.title = element_text(hjust = 0.5)) +
  theme_bw()

```

```{r}
# Plot 2:
spiny_counts %>%
  ggplot(aes(x = mpa, y = counts, fill = mpa)) +
  geom_violin(alpha = 0.8) +
  labs(title = "Lobster Counts by MPA Status", x = "MPA Status", y = "Lobster Count")+
  theme_minimal() +
scale_fill_manual(values = c("#ADD8E6", "#8B3A3A")) +
  theme(plot.title = element_text(hjust = 0.5),legend.position = "none")

```

```{r}
# plot 3: 

tidydata %>%
  ggplot(aes(x = factor(year), y = count)) +
  geom_boxplot(fill = "#EA7769", outlier.shape = NA) +
  geom_jitter(width = 0.1, alpha = 0.1) +
    ylim(0,15) +
  labs(x = "Year", y = "Lobster counts", title = "Lobster Count Distribution by Year") +
    theme(plot.title = element_text(hjust = 0.5)) +
  theme_bw() 

tidydata %>% 
    ggplot(aes(x = count, y = factor(year))) +
 ggridges::geom_density_ridges(rel_min_height = 0.001, scale = 3) +
  labs(x = "Year", y = "Lobster counts", title = "Lobster Count Distribution by Year") +
  theme_bw() +
    xlim(0,20) +
    theme(plot.title = element_text(hjust = 0.5))


```

```{r}
# plot 4: 
```

**c.** Compare means of the outcome by treatment group. Using the `tbl_summary()` function from the package [`gt_summary`](https://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html) 

```{r}
# USE: gt_summary::tbl_summary()

# ....Treatment summary.... 
treatment_sum <- spiny_counts %>%  
    # Group by mpa
    tbl_summary(by = mpa,
                # Include mean of outcome (count, size)
                include = c(count, size_mm),
                # Stat = mean 
                statistic = list(all_continuous()~ "{mean}"), 
                # Remove unknowns 
                missing = "no", 
                label = list(
      count   ~ "Lobster count",
      size_mm ~ "Carapace length (mm)"
    )) %>% 
    bold_labels()

treatment_sum

#.... Make pretty with {gt}....

treatment_sum %>% 
  as_gt() %>% 
  
  tab_header(
    title = "Lobster Population Metrics Across MPA Status",
    subtitle = "Marine Protected Areas Lobster Count and Size"
  ) %>% 
  
  tab_spanner(
    label = "MPA Status", 
    columns = c(stat_1, stat_2)
  ) %>% 
  
  cols_label(
    label = "Variable",
    stat_1 = "MPA", 
    stat_2 = "Non-MPA"
  ) %>% 
  
  tab_source_note(
    source_note = "Note: Reed et al., 2019"
  )

```

------------------------------------------------------------------------

#### Step 4: OLS regression- building intuition

**a.** Start with a simple OLS estimator of lobster counts regressed on treatment. Use the function `summ()` from the [`jtools`](https://jtools.jacob-long.com/) package to print the OLS output

**b.** Interpret the intercept & predictor coefficients *in your own words*. Use full sentences and write your interpretation of the regression results to be as clear as possible to a non-academic audience.

```{r}
# NOTE: We will not evaluate/interpret model fit in this assignment (e.g., R-square)

m1_ols <- lm(counts ~ treat, data = spiny_counts)

summ(m1_ols, model.fit = FALSE) 

#....Extract Coefficients....
intercept_m1_ols <- m1_ols$coefficients[1]
treat_m1_ols <- m1_ols$coefficients[2]

#....PUT IN TABLE

```
Interpretation:
The average lobster count for non-MPA sites is 28.17. For treated or MPA sites, lobster count is on average 15.20 more lobsters than non-MPA sites.   

**c.** Check the model assumptions using the `check_model` function from the `performance` package

**d.** Explain the results of the 4 diagnostic plots. Why are we getting this result?

```{r}
check_model(m1_ols,  check = "qq" )
```
This QQ plot demonstrates the normality of the residuals of the model. Since the points do not follow the green line, this signifies non-normality. If the data followed a normal pattern, the data points would follow the diagonal line. This plot shows that the data is skewed, which could be because lobster counts 

```{r}
check_model(m1_ols, check = "normality")
```
This graph of the density of the residuals shows that the data does not follow a normal distribution and is right skewed. 

```{r}
check_model(m1_ols, check = "homogeneity")
```
This plot demonstrates the "Homogeneity of Variance", which is a plot of fitted values with residuals. Since the data behaves non-normally, there is not a linear relationship between the fitted values and residuals and instead, the data curves. 

```{r}
check_model(m1_ols, check = "pp_check")
```
This final plot shows that the OLS regression model underpredicts the data. The data is demonstrating stronger variance than expected for this model. 

------------------------------------------------------------------------

#### Step 5: Fitting GLMs

**a.** Estimate a Poisson regression model using the `glm()` function

```{r}
#HINT1: Incidence Ratio Rate (IRR): Exponentiation of beta returns coefficient which is interpreted as the 'percent change' for a one unit increase in the predictor 

#HINT2: For the second glm() argument `family` use the following specification option `family = poisson(link = "log")`

m2_pois <- glm(counts ~ treat, 
               family = poisson(link = "log"), 
               data = spiny_counts)

summ(m2_pois, model.fit = FALSE) 

#....Extract Coefficients....
intercept_m2_pois <- m2_pois$coefficients[1]
treat_m2_pois <- m2_pois$coefficients[2]

#....Interpret Coefficients...
iir_int_m2_pois <- exp(intercept_m2_pois)
iir_treat_m2_pois <- (exp(treat_m2_pois)-1)*100 

#....Add to table....

```
**b.** Interpret the predictor coefficient in your own words. Use full sentences and write your interpretation of the results to be as clear as possible to a non-academic audience.

A Poisson model is used to determine the relationship between predictor and response when the response are count values. For this model, we are assessing the relationship between treatment or if the site is an MPA or not an MPA and the number of lobster in the site. The predictor coefficient for this model means that on average, MPA sites have 53.7% more lobsters than non-MPA sites. 

**c.** Explain the statistical concept of dispersion and overdispersion in the context of this model. 

A key assumption with Poisson models is that the variance of the data is equal the mean of the data. This is the dispersion of the data. In terms of this model, a normally dispersed data would point to 10 lobsters with 10 variance, however this data is overdispersed. Overdispersion is when the data's variance is greater than the mean. For lobster count data, this can be because certain sites might have more lobster counts, as you can see in `Fig 1.`. 

**d.** Compare results with previous model, explain change in the significance of the treatment effect. 

Compared to `m1_ols`, the standard errors for `m2_pois` show that this model fits the coefficients with more certainty. 

**e.** Check the model assumptions. Explain results.

```{r}
check_model(m2_pois)
```
**f.** Conduct tests for over-dispersion & zero-inflation. Explain results.
```{r}
check_overdispersion(m2_pois)
```
This overdispersion test shows that the dispersion ratio is 20.176. This is a ratio of  the observed variance to the expected variance and since it is greater than 1 (perfect dispersion), this signifies overdispersion within the data. 

```{r}
check_zeroinflation(m2_pois)
```
A good practice for determining models is to check if zero values are inflating the statistical analysis for the data. For count data, it is expected that zero values are going to be prevalent, however for this data there are no observed zeros. This can be confired with the following code:
```{r}
range(spiny_counts$counts)
```

**g.** Fit a negative binomial model using the function glm.nb() from the package `MASS` and check model diagnostics 

**h.** In 1-2 sentences explain rationale for fitting this GLM model.


```{r}
library(MASS) ## NOTE: The `select()` function is masked. Use: `dplyr::select()` ##
```

```{r}

# NOTE: The `glm.nb()` function does not require a `family` argument

m3_nb <- glm.nb(counts ~ treat, data = spiny_counts)
    
summ(m3_nb, model.fit = FALSE) 

```
**i.** Interpret the treatment estimate result in your own words. Compare with results from the previous model.


```{r}
check_overdispersion(m3_nb)
```

```{r}
check_zeroinflation(m3_nb)
```

```{r}
check_predictions(m3_nb)
```

```{r}
check_model(m3_nb)
```


------------------------------------------------------------------------

#### Step 6: Compare models 

**a.** Use the `export_summ()` function from the `jtools` package to look at the three regression models you fit side-by-side.

**c.** Write a short paragraph comparing the results. Is the treatment effect `robust` or stable across the model specifications. 

```{r}

export_summs(# ADD MODELS
             model.names = c("OLS","Poisson", "NB"),
             statistics = "none")

```

------------------------------------------------------------------------

#### Step 7: Building intuition - fixed effects

**a.** Create  new `df` with the `year` variable converted to a factor

**b.** Run the following negative binomial model using `glm.nb()`

- Add fixed effects for `year` (i.e., dummy coefficients)
- Include an interaction term between variables `treat` & `year` (`treat*year`)

**c.** Take a look at the regression output. Each coefficient provides a comparison or the difference in means for a specific sub-group in the data. Informally, describe the what the model has estimated at a conceptual level (NOTE: you do not have to interpret coefficients individually)

**d.** Explain why the main effect for treatment is negative? *Does this result make sense?

```{r}

ff_counts <- spiny_counts %>% 
    mutate(year=as_factor(year))
    
m5_fixedeffs <- glm.nb(
    counts ~ 
        treat +
        year +
        treat*year,
    data = ff_counts)

summ(m5_fixedeffs, model.fit = FALSE)
```

**e.** Look at the model predictions: Use the `interact_plot()` function from package `interactions` to plot mean predictions by year and treatment status. 

**f.** Re-evaluate your responses (c) and (b) above. 

```{r}

interact_plot(m5_fixedeffs, pred = year, modx = treat,
              outcome.scale = "link") # NOTE: y-axis on log-scale

# HINT: Change `outcome.scale` to "response" to convert y-axis scale to counts
```

**g.** Using `ggplot()` create a plot in same style as the previous `interaction plot`, but displaying the original scale of the outcome variable (lobster counts). This type of plot is commonly used to show how the treatment effect changes across discrete time points (i.e., panel data).

The plot should have... 
- `year` on the x-axis
- `counts` on the y-axis
- `mpa` as the grouping variable


```{r}
# Hint 1: Group counts by `year` and `mpa` and calculate the `mean_count`
# Hint 2: Convert variable `year` to a factor

plot_counts <- 

# plot_counts %>% ggplot() ...
```

------------------------------------------------------------------------

#### Step 8: Reconsider causal identification assumptions

a. Discuss whether you think `spillover effects` are likely in this research context (see Glossary of terms; https://docs.google.com/document/d/1RIudsVcYhWGpqC-Uftk9UTz3PIq6stVyEpT44EPNgpE/edit?usp=sharing)
b. Explain why spillover is an issue for the identification of causal effects
c. How does spillover relate to impact in this research setting?
d. Discuss the following causal inference assumptions in the context of the MPA treatment effect estimator. Evaluate if each of the assumption are reasonable: 
    
    1) SUTVA: Stable Unit Treatment Value assumption 
    2) Excludability assumption

------------------------------------------------------------------------

# EXTRA CREDIT

> Use the recent lobster abundance data with observations collected up until 2024 (`extracredit_sblobstrs24.csv`) to run an analysis evaluating the effect of MPA status on lobster counts using the same focal variables.

a. Create a new script for the analysis on the updated data
b. Run at least 3 regression models & assess model diagnostics
c. Compare and contrast results with the analysis from the 2012-2018 data sample (~ 2 paragraphs)


------------------------------------------------------------------------

![](figures/spiny1.png)

